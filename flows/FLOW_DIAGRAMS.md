# Visual Flow Diagrams

## üìä Complete System Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         RAG SYSTEM ARCHITECTURE                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   main.py    ‚îÇ  ‚Üê Entry Point (CLI)
                    ‚îÇ main() - L9  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  RAGSystem   ‚îÇ  ‚Üê Main Orchestrator
                    ‚îÇ __init__ L27 ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                  ‚îÇ                  ‚îÇ
        ‚ñº                  ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇPDF Processor ‚îÇ  ‚îÇVector Store  ‚îÇ  ‚îÇEmbedding &  ‚îÇ
‚îÇextract L8    ‚îÇ  ‚îÇ__init__ L16  ‚îÇ  ‚îÇembedder L39  ‚îÇ
‚îÇchunk L30     ‚îÇ  ‚îÇadd_doc L33   ‚îÇ  ‚îÇmodel L49     ‚îÇ
‚îÇ              ‚îÇ  ‚îÇsearch L67    ‚îÇ  ‚îÇ              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÑ Loading a PDF - Detailed Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PDF LOADING PROCESS                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

User Command:
python main.py load document.pdf
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 1: Parse Command & Initialize                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  main.main() - line 9                                           ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí Parse arguments (line 33)                                ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí Create RAGSystem (line 41)                               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  RAGSystem.__init__() - rag_system.py:27                        ‚îÇ
‚îÇ    ‚Ä¢ Load Sentence Transformer (line 39)                      ‚îÇ
‚îÇ    ‚Ä¢ Connect to Google Gemini API (line 47-49)                  ‚îÇ
‚îÇ    ‚Ä¢ Initialize VectorStore (line 50)                           ‚îÇ
‚îÇ      ‚îî‚îÄ‚Üí VectorStore.__init__() - vector_store.py:16            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 2: Extract Text from PDF                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  main.main() calls rag.load_pdf() - main.py:49                  ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí RAGSystem.load_pdf() - rag_system.py:52                  ‚îÇ
‚îÇ        ‚îî‚îÄ‚Üí extract_text_from_pdf() - pdf_processor.py:8         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Function: extract_text_from_pdf(pdf_path)                     ‚îÇ
‚îÇ  File: pdf_processor.py, Line: 8                                ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  PDF File                                                       ‚îÇ
‚îÇ    ‚îÇ                                                            ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí Page 1: "Introduction to machine learning..."           ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí Page 2: "Neural networks are..."                       ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí Page 3: "Deep learning uses..."                        ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí ...                                                      ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Result: "Introduction to machine learning... Neural networks   ‚îÇ
‚îÇ           are... Deep learning uses..."                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 3: Chunk Text                                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  RAGSystem.load_pdf() calls chunk_text() - rag_system.py:67     ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí chunk_text() - pdf_processor.py:30                       ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Function: chunk_text(text, chunk_size=1000, overlap=200)      ‚îÇ
‚îÇ  File: pdf_processor.py, Line: 30                              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Input:  "Very long text..." (10,000 characters)               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Process:                                                       ‚îÇ
‚îÇ    Chunk 1: [0:1000]     "Introduction to machine..."          ‚îÇ
‚îÇ    Chunk 2: [800:1800]   "...machine learning. Neural..."      ‚îÇ
‚îÇ    Chunk 3: [1600:2600]  "...Neural networks are..."           ‚îÇ
‚îÇ    ...                                                          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Result: ["Chunk 1...", "Chunk 2...", "Chunk 3...", ...]       ‚îÇ
‚îÇ          (~10 chunks for 10k chars)                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 4: Generate Embeddings                                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  RAGSystem.load_pdf() - rag_system.py:72                       ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí self.embedder.encode(chunks)                            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Function: embedder.encode()                                    ‚îÇ
‚îÇ  Location: rag_system.py, Line: 72                              ‚îÇ
‚îÇ  (Sentence Transformer library method)                         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Input:  ["Chunk 1...", "Chunk 2...", ...]                     ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Process:                                                       ‚îÇ
‚îÇ    Chunk 1 ‚Üí [0.23, -0.45, 0.67, ..., 0.12]  (384 numbers)    ‚îÇ
‚îÇ    Chunk 2 ‚Üí [0.25, -0.43, 0.65, ..., 0.11]  (384 numbers)    ‚îÇ
‚îÇ    Chunk 3 ‚Üí [0.28, -0.41, 0.63, ..., 0.15]  (384 numbers)    ‚îÇ
‚îÇ    ...                                                          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Result: [[0.23, -0.45, ...], [0.25, -0.43, ...], ...]         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 5: Store in Vector Database                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  RAGSystem.load_pdf() calls vector_store.add_document()        ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí rag_system.py:78                                         ‚îÇ
‚îÇ        ‚îî‚îÄ‚Üí VectorStore.add_document() - vector_store.py:33     ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Function: VectorStore.add_document(chunks, embeddings, doc)   ‚îÇ
‚îÇ  File: vector_store.py, Line: 33                               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ChromaDB Collection:                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ ID              ‚îÇ Embedding      ‚îÇ Text        ‚îÇ Metadata‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
‚îÇ  ‚îÇ doc_chunk_0    ‚îÇ [0.23, -0.45..]‚îÇ "Chunk 1..." ‚îÇ doc.pdf ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ doc_chunk_1    ‚îÇ [0.25, -0.43..]‚îÇ "Chunk 2..." ‚îÇ doc.pdf ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ doc_chunk_2    ‚îÇ [0.28, -0.41..]‚îÇ "Chunk 3..." ‚îÇ doc.pdf ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ...            ‚îÇ ...            ‚îÇ ...         ‚îÇ ...     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Saved to: chroma_db/ folder (persistent)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚úÖ PDF Successfully Loaded!
```

---

## üîç Querying - Detailed Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    QUERY PROCESS                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

User Command:
python main.py query "What is machine learning?"
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 1: Parse Command & Check Documents                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  main.main() - line 9                                          ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí Parse arguments (line 33)                               ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí Create RAGSystem (line 41)                              ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí Call rag.query() - main.py:56                           ‚îÇ
‚îÇ        ‚îî‚îÄ‚Üí RAGSystem.query() - rag_system.py:81                ‚îÇ
‚îÇ            ‚îî‚îÄ‚Üí Check if documents loaded (line 92)            ‚îÇ
‚îÇ                ‚îî‚îÄ‚Üí vector_store.get_chunk_count() - vector_store.py:135
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 2: Convert Question to Embedding                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  RAGSystem.query() - rag_system.py:96                          ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí self.embedder.encode(question)                           ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Function: embedder.encode()                                   ‚îÇ
‚îÇ  Location: rag_system.py, Line: 96                             ‚îÇ
‚îÇ  (Sentence Transformer library method)                         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Input:  "What is machine learning?"                            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Process:                                                       ‚îÇ
‚îÇ    Question ‚Üí [0.25, -0.43, 0.65, ..., 0.12]                   ‚îÇ
‚îÇ              (384 numbers representing the question)            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Result: query_vector = [0.25, -0.43, 0.65, ..., 0.12]         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 3: Search for Similar Chunks                               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  RAGSystem.query() calls vector_store.search() - rag_system.py:99
‚îÇ    ‚îî‚îÄ‚Üí VectorStore.search() - vector_store.py:67              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Function: VectorStore.search(query_embedding, top_k=3)        ‚îÇ
‚îÇ  File: vector_store.py, Line: 67                               ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Process:                                                       ‚îÇ
‚îÇ    1. Convert embedding to list (line 79)                      ‚îÇ
‚îÇ    2. Query ChromaDB (line 82)                                 ‚îÇ
‚îÇ    3. Format results (line 88-97)                              ‚îÇ
‚îÇ    4. Return top 3                                             ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Similarity Scores:                                             ‚îÇ
‚îÇ    Chunk 1: "Machine learning is..." ‚Üí 0.92 (92% match) ‚úì      ‚îÇ
‚îÇ    Chunk 2: "ML algorithms..."      ‚Üí 0.85 (85% match) ‚úì        ‚îÇ
‚îÇ    Chunk 3: "AI and ML..."         ‚Üí 0.82 (82% match) ‚úì        ‚îÇ
‚îÇ    Chunk 4: "Python programming..." ‚Üí 0.15 (15% match) ‚úó       ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Result: Top 3 chunks with highest similarity                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 4: Build Context Prompt                                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  RAGSystem.query() - rag_system.py:105                         ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí Build context string (line 105)                         ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí Construct prompt (line 108-116)                         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Function: RAGSystem.query() (prompt building)                 ‚îÇ
‚îÇ  File: rag_system.py, Lines: 105-116                           ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Context:                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ [From document.pdf]                                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ Machine learning is a subset of artificial intelligence ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ that enables systems to learn from data...              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ [From document.pdf]                                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ ML algorithms can be supervised or unsupervised...       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ [From document.pdf]                                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ AI and ML are closely related fields...                 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Question: "What is machine learning?"                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ STEP 5: Generate Answer with Gemini AI                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  RAGSystem.query() - rag_system.py:119                         ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí self.model.generate_content(prompt)                     ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Function: model.generate_content()                            ‚îÇ
‚îÇ  Location: rag_system.py, Line: 119                            ‚îÇ
‚îÇ  (Google Gemini API call)                                      ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Input to Gemini:                                               ‚îÇ
‚îÇ  """                                                            ‚îÇ
‚îÇ  You are a helpful assistant...                                 ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Context from documents:                                        ‚îÇ
‚îÇ  [From document.pdf]                                            ‚îÇ
‚îÇ  Machine learning is a subset of AI...                          ‚îÇ
‚îÇ  ...                                                            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Question: What is machine learning?                            ‚îÇ
‚îÇ  """                                                            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Gemini Processing:                                             ‚îÇ
‚îÇ    1. Reads context                                             ‚îÇ
‚îÇ    2. Understands question                                      ‚îÇ
‚îÇ    3. Generates answer based on context                         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Output:                                                        ‚îÇ
‚îÇ  "Machine learning is a subset of artificial intelligence       ‚îÇ
‚îÇ   that enables systems to learn and improve from experience    ‚îÇ
‚îÇ   without being explicitly programmed..."                       ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Return to main.py (line 56) ‚Üí Display answer (line 59)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚úÖ Answer Returned to User
```

---

## üîó Component Interactions

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    COMPONENT INTERACTION DIAGRAM                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   User       ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ Commands
                           ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   main.py    ‚îÇ
                    ‚îÇ main() L9    ‚îÇ
                    ‚îÇ              ‚îÇ
                    ‚îÇ  ‚Ä¢ Parse CLI ‚îÇ
                    ‚îÇ  ‚Ä¢ Route cmds‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚îÇ Creates
                           ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  RAGSystem   ‚îÇ
                    ‚îÇ __init__ L27 ‚îÇ
                    ‚îÇ              ‚îÇ
                    ‚îÇ  ‚Ä¢ Orchestrates‚îÇ
                    ‚îÇ  ‚Ä¢ Manages   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ      ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                                      ‚îÇ
        ‚ñº                                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇPDF Processor ‚îÇ                      ‚îÇVector Store   ‚îÇ
‚îÇextract L8    ‚îÇ                      ‚îÇ__init__ L16   ‚îÇ
‚îÇchunk L30     ‚îÇ                      ‚îÇadd_doc L33    ‚îÇ
‚îÇ              ‚îÇ                      ‚îÇsearch L67     ‚îÇ
‚îÇ‚Ä¢ Extract    ‚îÇ                      ‚îÇ‚Ä¢ Add docs    ‚îÇ
‚îÇ‚Ä¢ Chunk      ‚îÇ                      ‚îÇ‚Ä¢ Search      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ‚Ä¢ Persist     ‚îÇ
                                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚îÇ
                                             ‚îÇ Uses
                                             ‚ñº
                                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                      ‚îÇ  ChromaDB    ‚îÇ
                                      ‚îÇ  (Database)  ‚îÇ
                                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  RAGSystem   ‚îÇ
                    ‚îÇ load_pdf L52 ‚îÇ
                    ‚îÇ query L81    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ      ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                                      ‚îÇ
        ‚ñº                                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇSentence      ‚îÇ                      ‚îÇGoogle Gemini ‚îÇ
‚îÇTransformer   ‚îÇ                      ‚îÇ              ‚îÇ
‚îÇencode L72    ‚îÇ                      ‚îÇgenerate L119 ‚îÇ
‚îÇencode L96    ‚îÇ                      ‚îÇ              ‚îÇ
‚îÇ              ‚îÇ                      ‚îÇ‚Ä¢ Generate    ‚îÇ
‚îÇ‚Ä¢ Encode text ‚îÇ                      ‚îÇ  answers     ‚îÇ
‚îÇ‚Ä¢ Create      ‚îÇ                      ‚îÇ              ‚îÇ
‚îÇ  embeddings  ‚îÇ                      ‚îÇ              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üì¶ Data Structures Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DATA TRANSFORMATION PIPELINE                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

PDF File (binary)
    ‚îÇ
    ‚ñº
String (text)
    "Introduction to machine learning. Neural networks..."
    ‚îÇ
    ‚ñº
List[String] (chunks)
    [
      "Introduction to machine learning. Neural...",
      "...learning. Neural networks are...",
      "...networks are computational models..."
    ]
    ‚îÇ
    ‚ñº
List[np.ndarray] (embeddings)
    [
      array([0.23, -0.45, 0.67, ..., 0.12]),  # 384 numbers
      array([0.25, -0.43, 0.65, ..., 0.11]),  # 384 numbers
      array([0.28, -0.41, 0.63, ..., 0.15])   # 384 numbers
    ]
    ‚îÇ
    ‚ñº
ChromaDB Storage
    {
      ids: ["doc_chunk_0", "doc_chunk_1", ...],
      embeddings: [[0.23, -0.45, ...], [0.25, -0.43, ...], ...],
      documents: ["Chunk 1...", "Chunk 2...", ...],
      metadatas: [{"document_name": "doc.pdf"}, ...]
    }
    ‚îÇ
    ‚ñº
Query Time:
    Question String
        ‚îÇ
        ‚ñº
    Query Vector (np.ndarray)
        ‚îÇ
        ‚ñº
    Search Results: List[Tuple]
        [
          ("Chunk text...", 0.92, "doc.pdf"),  # (text, score, doc)
          ("Chunk text...", 0.85, "doc.pdf"),
          ("Chunk text...", 0.82, "doc.pdf")
        ]
        ‚îÇ
        ‚ñº
    Prompt String
        "Context: ...\nQuestion: ..."
        ‚îÇ
        ‚ñº
    Answer String
        "Machine learning is..."
```

---

## üéØ Similarity Search Visualization

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              HOW SIMILARITY SEARCH WORKS                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Stored Chunks in Database:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Chunk 1: "Machine learning is a subset of AI"                   ‚îÇ
‚îÇ Vector: [0.23, -0.45, 0.67, ..., 0.12]                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Chunk 2: "Python is a programming language"                     ‚îÇ
‚îÇ Vector: [0.89, 0.12, -0.34, ..., -0.56]                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Chunk 3: "Deep learning uses neural networks"                   ‚îÇ
‚îÇ Vector: [0.28, -0.41, 0.63, ..., 0.15]                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

User Question:
"What is machine learning?"
Vector: [0.25, -0.43, 0.65, ..., 0.11]

Similarity Calculation:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Question vs Chunk 1:                                              ‚îÇ
‚îÇ   Cosine Similarity = 0.92 (92% similar) ‚úì TOP MATCH            ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ Question vs Chunk 3:                                              ‚îÇ
‚îÇ   Cosine Similarity = 0.78 (78% similar) ‚úì RELEVANT             ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ Question vs Chunk 2:                                              ‚îÇ
‚îÇ   Cosine Similarity = 0.15 (15% similar) ‚úó NOT RELEVANT         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Results (top_k=3):
1. Chunk 1 (score: 0.92) ‚Üê Most relevant
2. Chunk 3 (score: 0.78) ‚Üê Relevant
3. Chunk 2 (score: 0.15) ‚Üê Less relevant, but included
```

---

## üîÑ Complete End-to-End Flow

```
START
  ‚îÇ
  ‚îú‚îÄ‚Üí [User] python main.py load doc.pdf
  ‚îÇ
  ‚îú‚îÄ‚Üí [main.py] main() - line 9
  ‚îÇ     ‚îî‚îÄ‚Üí Parse command (line 33)
  ‚îÇ     ‚îî‚îÄ‚Üí Create RAGSystem() (line 41)
  ‚îÇ           ‚îî‚îÄ‚Üí RAGSystem.__init__() - rag_system.py:27
  ‚îÇ                 ‚Ä¢ Load Sentence Transformer (line 39)
  ‚îÇ                 ‚Ä¢ Connect Gemini API (line 47-49)
  ‚îÇ                 ‚Ä¢ VectorStore.__init__() - vector_store.py:16
  ‚îÇ
  ‚îú‚îÄ‚Üí [RAGSystem] load_pdf("doc.pdf") - rag_system.py:52
  ‚îÇ     ‚îÇ
  ‚îÇ     ‚îú‚îÄ‚Üí [PDF Processor] extract_text_from_pdf() - pdf_processor.py:8
  ‚îÇ     ‚îÇ     ‚îî‚îÄ‚Üí "Full text content..."
  ‚îÇ     ‚îÇ
  ‚îÇ     ‚îú‚îÄ‚Üí [PDF Processor] chunk_text() - pdf_processor.py:30
  ‚îÇ     ‚îÇ     ‚îî‚îÄ‚Üí ["Chunk 1", "Chunk 2", ...]
  ‚îÇ     ‚îÇ
  ‚îÇ     ‚îú‚îÄ‚Üí [Sentence Transformer] embedder.encode() - rag_system.py:72
  ‚îÇ     ‚îÇ     ‚îî‚îÄ‚Üí [[0.23, ...], [0.25, ...], ...]
  ‚îÇ     ‚îÇ
  ‚îÇ     ‚îî‚îÄ‚Üí [Vector Store] add_document() - vector_store.py:33
  ‚îÇ           ‚îî‚îÄ‚Üí Persisted to disk (ChromaDB)
  ‚îÇ
  ‚îî‚îÄ‚Üí ‚úÖ PDF Loaded
        ‚îÇ
        ‚îú‚îÄ‚Üí [User] python main.py query "Question?"
        ‚îÇ
        ‚îú‚îÄ‚Üí [main.py] main() - line 9
        ‚îÇ     ‚îî‚îÄ‚Üí rag.query() - main.py:56
        ‚îÇ           ‚îî‚îÄ‚Üí RAGSystem.query() - rag_system.py:81
        ‚îÇ                 ‚îÇ
        ‚îÇ                 ‚îú‚îÄ‚Üí [Sentence Transformer] embedder.encode() - rag_system.py:96
        ‚îÇ                 ‚îÇ     ‚îî‚îÄ‚Üí [0.25, -0.43, ...]
        ‚îÇ                 ‚îÇ
        ‚îÇ                 ‚îú‚îÄ‚Üí [Vector Store] search() - vector_store.py:67
        ‚îÇ                 ‚îÇ     ‚îî‚îÄ‚Üí Top 3 chunks found
        ‚îÇ                 ‚îÇ
        ‚îÇ                 ‚îú‚îÄ‚Üí [RAGSystem] Build prompt - rag_system.py:105-116
        ‚îÇ                 ‚îÇ     ‚îî‚îÄ‚Üí Context + Question
        ‚îÇ                 ‚îÇ
        ‚îÇ                 ‚îî‚îÄ‚Üí [Gemini API] model.generate_content() - rag_system.py:119
        ‚îÇ                       ‚îî‚îÄ‚Üí "Answer text..."
        ‚îÇ
        ‚îî‚îÄ‚Üí ‚úÖ Answer displayed (main.py:59)
```

---

## üíæ Persistence Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DATA PERSISTENCE                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Session 1:
  Load PDF ‚Üí ChromaDB ‚Üí Save to chroma_db/ folder
    ‚îÇ
    ‚îî‚îÄ‚Üí RAGSystem.load_pdf() - rag_system.py:78
        ‚îî‚îÄ‚Üí VectorStore.add_document() - vector_store.py:33
            ‚îî‚îÄ‚Üí ChromaDB saves automatically (line 60-65)
    ‚îÇ
    ‚îî‚îÄ‚Üí chroma_db/
        ‚îú‚îÄ‚îÄ chroma.sqlite3 (metadata)
        ‚îî‚îÄ‚îÄ [collection_id]/
            ‚îú‚îÄ‚îÄ data_level0.bin
            ‚îú‚îÄ‚îÄ header.bin
            ‚îî‚îÄ‚îÄ ...

Session 2 (Restart):
  Start RAGSystem ‚Üí ChromaDB loads from chroma_db/
    ‚îÇ
    ‚îî‚îÄ‚Üí RAGSystem.__init__() - rag_system.py:50
        ‚îî‚îÄ‚Üí VectorStore.__init__() - vector_store.py:16
            ‚îî‚îÄ‚Üí chromadb.PersistentClient() loads existing data (line 24)
    ‚îÇ
    ‚îî‚îÄ‚Üí All previous documents available!
        ‚îÇ
        ‚îî‚îÄ‚Üí Can query immediately without reloading

Clear Command:
  python main.py clear
    ‚îÇ
    ‚îî‚îÄ‚Üí main.main() - main.py:75
        ‚îî‚îÄ‚Üí RAGSystem.clear() - rag_system.py:131
            ‚îî‚îÄ‚Üí VectorStore.clear() - vector_store.py:101
                ‚îî‚îÄ‚Üí Deletes collection (line 105) ‚Üí chroma_db/ folder cleared
```

---

## üìã Function Reference Table

Quick reference for all key functions with their file locations and line numbers:

| Function Name | File | Line | Purpose |
|--------------|------|------|---------|
| `main()` | main.py | 9 | CLI entry point, parses commands |
| `RAGSystem.__init__()` | rag_system.py | 27 | Initialize RAG system, load models |
| `RAGSystem.load_pdf()` | rag_system.py | 52 | Load and process PDF file |
| `RAGSystem.query()` | rag_system.py | 81 | Answer questions using RAG |
| `RAGSystem.list_documents()` | rag_system.py | 122 | List all loaded documents |
| `RAGSystem.clear()` | rag_system.py | 131 | Clear all documents |
| `extract_text_from_pdf()` | pdf_processor.py | 8 | Extract text from PDF file |
| `chunk_text()` | pdf_processor.py | 30 | Split text into chunks |
| `VectorStore.__init__()` | vector_store.py | 16 | Initialize ChromaDB |
| `VectorStore.add_document()` | vector_store.py | 33 | Store chunks and embeddings |
| `VectorStore.search()` | vector_store.py | 67 | Search for similar chunks |
| `VectorStore.clear()` | vector_store.py | 101 | Clear all stored data |
| `VectorStore.get_document_list()` | vector_store.py | 114 | Get list of document names |
| `VectorStore.get_chunk_count()` | vector_store.py | 135 | Get total chunk count |

### External Library Functions Used:

| Function/Method | Library | Used In | Line |
|----------------|---------|---------|------|
| `embedder.encode()` | Sentence Transformers | rag_system.py | 72, 96 |
| `model.generate_content()` | Google Gemini API | rag_system.py | 119 |
| `chromadb.PersistentClient()` | ChromaDB | vector_store.py | 24 |

---

*These diagrams show the complete flow of data and control through your RAG system with function names and line numbers for easy code navigation!*



## Detailed Condition Flows (File / Function / Lines / Next Step)

### 1. `backend/main.py::upload` (L168‚ÄìL286)

| File            | Function | Lines     | Condition / Step                                   | If Condition TRUE (failure)                                                              | If Condition FALSE (next step)                                     |
|----------------|----------|-----------|----------------------------------------------------|------------------------------------------------------------------------------------------|--------------------------------------------------------------------|
| backend/main.py | upload  | 175‚Äì184   | `if not vector_store`                             | Log `UPLOAD STEP 1 FAILED`; raise `HTTPException(500, "Vector store not initialized")`   | Log `UPLOAD STEP 1 COMPLETE`; go to Step 2 (validate files)       |
| backend/main.py | upload  | 186‚Äì193   | `if not files`                                    | Log `UPLOAD STEP 2 FAILED`; raise `HTTPException(400, "No files provided")`              | Log `UPLOAD STEP 2 COMPLETE`; enter loop `for idx, file in files` |
| backend/main.py | upload  | 206‚Äì218   | `if not file_ext or file_ext not in allowed_extensions` | Log `UPLOAD STEP 3.{idx}.1 FAILED`; append `status="error"` result; increment `error_count` | Log `UPLOAD STEP 3.{idx}.1 COMPLETE`; go to size validation       |
| backend/main.py | upload  | 225‚Äì233   | `if file_size > settings.MAX_FILE_SIZE`           | Log `UPLOAD STEP 3.{idx}.2 FAILED`; append size `error` result; increment `error_count`  | Continue to zero-size check                                        |
| backend/main.py | upload  | 235‚Äì243   | `if file_size == 0`                               | Log `UPLOAD STEP 3.{idx}.2 FAILED`; append ‚ÄúFile is empty‚Äù; increment `error_count`      | Log `UPLOAD STEP 3.{idx}.2 COMPLETE`; call `ingestor.process_uploaded_file` |
| backend/main.py | upload  | 251‚Äì262   | `if chunks`                                       | Log `UPLOAD STEP 3.{idx}.4`; call `vector_store.add_chunks`; append `status="ok"` result; `success_count++` | Log path; already in success branch                               |
| backend/main.py | upload  | 263‚Äì269   | `else` (no chunks)                                | Log `UPLOAD STEP 3.{idx} FAILED: No chunks extracted`; append `status="error"` result; `error_count++` | N/A                                                                |
| backend/main.py | upload  | 271‚Äì273   | `except HTTPException`                            | Log `UPLOAD STEP 3.{idx} FAILED`; re-raise `HTTPException`                               | N/A                                                                |
| backend/main.py | upload  | 274‚Äì281   | `except Exception as e`                           | Log `UPLOAD STEP 3.{idx} FAILED: Error processing file`; append `status="error"` result; `error_count++` | N/A                                                                |
| backend/main.py | upload  | 283‚Äì286   | Finalize                                          | Log `UPLOAD ... COMPLETE` with success/error counts and total chunks; return JSON        | N/A                                                                |


### 2. `backend/ingest.py::process_uploaded_file` (L540‚ÄìL603)

| File             | Function              | Lines    | Condition / Step                                      | If Condition TRUE (failure)                                                         | If Condition FALSE (next step)                          |
|-----------------|-----------------------|----------|-------------------------------------------------------|-------------------------------------------------------------------------------------|---------------------------------------------------------|
| backend/ingest.py | process_uploaded_file | 553‚Äì556 | `if not file_content` (STEP 1)                        | Log `STEP 1 FAILED: Empty file content provided`; return `([], "unknown")`         | Log `STEP 1 COMPLETE`; proceed to temp directory        |
| backend/ingest.py | process_uploaded_file | 560‚Äì566 | `try: temp_path.parent.mkdir(...)` (STEP 2)           | On exception: log `STEP 2 FAILED`; return `([], filename or "unknown")`            | Log `STEP 2 COMPLETE`; proceed to write temp file       |
| backend/ingest.py | process_uploaded_file | 569‚Äì576 | `try: open(temp_path, 'wb')` (STEP 3)                 | On exception: log `STEP 3 FAILED`; return `([], filename or "unknown")`            | Log `STEP 3 COMPLETE`; proceed to process document      |
| backend/ingest.py | process_uploaded_file | 579‚Äì588 | `try: load_and_process_documents([temp_path])` (STEP 4) | On exception: log `STEP 4 FAILED`; return `([], filename or "unknown")`           | If `chunks`: log `STEP 4 COMPLETE`; else log `STEP 4 FAILED`; return `(chunks, doc_name)` |
| backend/ingest.py | process_uploaded_file | 595‚Äì602 | `finally` cleanup (STEP 5)                            | If `unlink` fails: log `STEP 5 FAILED` warning; no change to returned result        | On success: log `STEP 5 COMPLETE` or debug              |


### 3. `backend/ingest.py::load_and_process_documents` (L37‚ÄìL113)

| File             | Function                    | Lines  | Condition / Step                                 | If Condition TRUE (failure)                                                | If Condition FALSE (next step)                           |
|-----------------|-----------------------------|--------|--------------------------------------------------|----------------------------------------------------------------------------|----------------------------------------------------------|
| backend/ingest.py | load_and_process_documents | 49‚Äì52  | `if not file_paths` (STEP 1)                     | Log `STEP 1 FAILED: No file paths provided`; return `([], "unknown")`      | Log `STEP 1 COMPLETE`; proceed to loop over file_paths   |
| backend/ingest.py | load_and_process_documents | 61‚Äì68  | `if not os.path.exists(file_path)` (STEP 2.{idx}) | Log `STEP 2.{idx} FAILED: File not found`; `failed_count++`; `continue`   | Log `STEP 2.{idx}.1 COMPLETE`; proceed to `_extract_text` |
| backend/ingest.py | load_and_process_documents | 72‚Äì84  | `try: text = self._extract_text(...)` (STEP 2.{idx}.2) | On exception: log `STEP 2.{idx} FAILED`; `failed_count++`; `continue`    | If `text.strip()`: append text + name; else log `FAILED` and `failed_count++` |
| backend/ingest.py | load_and_process_documents | 92‚Äì95  | `if not all_text.strip()` (STEP 3)               | Log `STEP 3 FAILED: No text extracted from any files`; return `([], "unknown")` | Log `STEP 3 COMPLETE`; proceed to chunking               |
| backend/ingest.py | load_and_process_documents | 98‚Äì107 | `try: chunks = self._chunk_text(all_text)` (STEP 4) | If `not chunks`: log `STEP 4 FAILED`; return `([], "unknown")`; on exception: log and return `([], "unknown")` | Log `STEP 4 COMPLETE`; continue                          |
| backend/ingest.py | load_and_process_documents | 110‚Äì113| STEP 5 result composition                        | Log flow COMPLETE; return `(chunks, doc_name)`                               | N/A                                                      |


### 4. `backend/rag_engine.py::answer_query_with_context` (L81‚Äì202)

| File               | Function                   | Lines   | Condition / Step                                     | If Condition TRUE (failure)                                                              | If Condition FALSE (next step)                       |
|-------------------|----------------------------|---------|------------------------------------------------------|------------------------------------------------------------------------------------------|------------------------------------------------------|
| backend/rag_engine.py | answer_query_with_context | 93‚Äì100 | `if not question or not question.strip()` (RAG STEP 1) | Log `RAG STEP 1 FAILED: Empty question provided`; return `"Please provide a valid question."` | Log `RAG STEP 1 COMPLETE`; proceed to LLM validation |
| backend/rag_engine.py | answer_query_with_context | 104‚Äì110| `if not self.llm_engine.is_ready()` (STEP 2)         | Log `RAG STEP 2 FAILED: LLM engine not ready`; return `"Error: LLM service not available..."` | Log `RAG STEP 2 COMPLETE`; proceed to search         |
| backend/rag_engine.py | answer_query_with_context | 114‚Äì126| `results = self.vector_store.search(...)` (STEP 3)   | On exception: log `RAG STEP 3 FAILED`; return `"Error searching documents: ..."`        | If `not results`: log `RAG STEP 3 FAILED`; return `"No documents found..."`; else continue |
| backend/rag_engine.py | answer_query_with_context | 135‚Äì151| Build context/sources (STEP 4)                      | On exception: log `RAG STEP 4 FAILED`; return `"Error building context: ..."`           | Log `RAG STEP 4 COMPLETE`; proceed to build prompt   |
| backend/rag_engine.py | answer_query_with_context | 160‚Äì170| Build prompt (STEP 5)                               | On exception: log `RAG STEP 5 FAILED`; return `"Error building prompt: ..."` plus context/sources | Log `RAG STEP 5 COMPLETE`; proceed to generate       |
| backend/rag_engine.py | answer_query_with_context | 173‚Äì195| Generate answer (STEP 6)                            | On exception: log `RAG STEP 6 FAILED`; return `"Error processing query: ..."`           | If `answer`: log COMPLETE and return; else return `"Error: Empty response from LLM."` |


### 5. `backend/vectorstore.py::search` (L165‚Äì225)

| File                | Function | Lines   | Condition / Step                              | If Condition TRUE (failure)                                        | If Condition FALSE (next step)                         |
|--------------------|----------|---------|-----------------------------------------------|--------------------------------------------------------------------|--------------------------------------------------------|
| backend/vectorstore.py | search | 179‚Äì182 | `if not self.chunks` (SEARCH STEP 1)          | Log `SEARCH STEP 1 FAILED: No chunks available`; return `[]`       | Log `SEARCH STEP 1 COMPLETE`; proceed to query validation      |
| backend/vectorstore.py | search | 185‚Äì187 | `if not query or not query.strip()` (STEP 2)  | Log `SEARCH STEP 2 FAILED: Empty query provided`; return `[]`     | Log `SEARCH STEP 2 COMPLETE`; proceed to embedding              |
| backend/vectorstore.py | search | 190‚Äì197 | Generate query embedding (STEP 3)             | On exception (caught as `SEARCH FAILED`): return `[]`             | Log `SEARCH STEP 3 COMPLETE`; proceed to index.search          |
| backend/vectorstore.py | search | 199‚Äì203 | `self.index.search(query_emb, k)` (STEP 4)    | On exception: log `SEARCH FAILED: Error during search`; return `[]` | Log `SEARCH STEP 4 COMPLETE`; proceed to processing results     |
| backend/vectorstore.py | search | 205‚Äì221 | Process `indices`/`distances` (STEP 5)        | Invalid indices: log warnings and skip those entries; only outer exception returns `[]` | On success: log `SEARCH COMPLETE` and return results   |


### 6. `backend/vectorstore.py::add_chunks` (L113‚Äì163)

| File                | Function   | Lines   | Condition / Step                                | If Condition TRUE (failure)                                            | If Condition FALSE (next step)                         |
|--------------------|------------|---------|-------------------------------------------------|------------------------------------------------------------------------|--------------------------------------------------------|
| backend/vectorstore.py | add_chunks | 123‚Äì126 | `if not chunks` (ADD_CHUNKS STEP 1)            | Log `ADD_CHUNKS STEP 1 FAILED: No chunks provided`; `return`           | Log `ADD_CHUNKS STEP 1 COMPLETE`; proceed to embeddings             |
| backend/vectorstore.py | add_chunks | 129‚Äì139 | Generate embeddings (STEP 2)                   | On exception: outer `except` logs `ADD_CHUNKS FAILED` and **raises**   | Log `ADD_CHUNKS STEP 2 COMPLETE`; proceed to shape validation       |
| backend/vectorstore.py | add_chunks | 141‚Äì147 | `if embeddings.shape[1] != self.embedding_dim` (STEP 3) | Log `ADD_CHUNKS STEP 3 FAILED: Dimension mismatch`; raise `ValueError` | Log `ADD_CHUNKS STEP 3 COMPLETE`; proceed to adding to index        |
| backend/vectorstore.py | add_chunks | 150‚Äì154 | Add to FAISS index (STEP 4)                    | On exception: outer `except` logs and **raises**                       | Log `ADD_CHUNKS STEP 4 COMPLETE`; proceed to save index             |
| backend/vectorstore.py | add_chunks | 156‚Äì160 | `_save_index()` (STEP 5)                       | On exception: outer `except` logs and **raises**                       | Log `ADD_CHUNKS STEP 5 COMPLETE` and flow COMPLETE                  |


### 7. `backend/main.py::init_components` (L66‚Äì113)

| File            | Function        | Lines   | Condition / Step                                             | If Condition TRUE (failure)                                                          | If Condition FALSE (next step)                                   |
|----------------|-----------------|---------|--------------------------------------------------------------|--------------------------------------------------------------------------------------|------------------------------------------------------------------|
| backend/main.py | init_components | 70‚Äì72  | Start init: log `"=== Starting RAG system initialization flow ==="` | N/A                                                                          | Proceed to STEP 1                                               |
| backend/main.py | init_components | 73‚Äì80  | STEP 1 ‚Äì create `DocumentIngestor(...)`                      | If `DocumentIngestor.__init__` raises: caught by outer `except`, log `INIT FAILED` and **re-raise** | Log `INIT STEP 1 COMPLETE`; proceed to STEP 2                    |
| backend/main.py | init_components | 82‚Äì89  | STEP 2 ‚Äì create `FAISSVectorStore(...)`                      | If `FAISSVectorStore.__init__` raises: caught, log `INIT FAILED`, **re-raise**      | Log `INIT STEP 2 COMPLETE` (chunks count); proceed to STEP 3     |
| backend/main.py | init_components | 91‚Äì97  | STEP 3 ‚Äì `llm_engine = get_llm_engine(...)` + `is_ready()`   | If `get_llm_engine` raises: caught, log `INIT FAILED`, **re-raise**; if LLM not ready: log `INIT STEP 3 FAILED` but continue | If ready: log `INIT STEP 3 COMPLETE`; then go to STEP 4          |
| backend/main.py | init_components | 99‚Äì107 | STEP 4 ‚Äì create `RAGEngine(...)`                             | If `RAGEngine.__init__` raises: caught, log `INIT FAILED`, **re-raise**            | Log `INIT STEP 4 COMPLETE`; log `INIT flow COMPLETE`            |
| backend/main.py | init_components | 111‚Äì113| Outer `except Exception as e`                                | Any failure in any step: log `INIT FAILED: Failed to initialize components: {e}`; **re-raise** | N/A                                                              |


### 8. `backend/main.py::chat` (L289‚Äì345)

| File            | Function | Lines   | Condition / Step                                                       | If Condition TRUE (failure)                                                                 | If Condition FALSE (next step)                                |
|----------------|----------|---------|------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|---------------------------------------------------------------|
| backend/main.py | chat     | 292‚Äì293| Start: log `"=== Starting chat endpoint flow for query: ... ==="`     | N/A                                                                                         | Proceed to STEP 1                                             |
| backend/main.py | chat     | 295‚Äì300| STEP 1 ‚Äì `if not rag_engine`                                          | Log `CHAT STEP 1 FAILED: RAG engine not initialized`; raise `HTTPException(500)`           | Log `CHAT STEP 1 COMPLETE`; proceed to STEP 2                 |
| backend/main.py | chat     | 304‚Äì309| STEP 2 ‚Äì `if not llm_engine or not llm_engine.is_ready()`             | Log `CHAT STEP 2 FAILED: LLM not ready`; raise `HTTPException(503)`                        | Log `CHAT STEP 2 COMPLETE`; proceed to STEP 3                 |
| backend/main.py | chat     | 313‚Äì318| STEP 3 ‚Äì `if not vector_store or not vector_store.chunks`             | Log `CHAT STEP 3 FAILED: No documents loaded`; raise `HTTPException(400)`                  | Log `CHAT STEP 3 COMPLETE` (chunks count); proceed to STEP 4  |
| backend/main.py | chat     | 323‚Äì325| STEP 4 ‚Äì set top_k and call `rag_engine.answer_query_with_context()`  | If `set_top_k` or RAG call raises: handled by `except` blocks below                        | On success, `result` dict is available; proceed to answer check |
| backend/main.py | chat     | 327‚Äì336| STEP 4 answer check ‚Äì `if result.get("answer")` else error            | If falsy: log `CHAT STEP 4 FAILED: Empty answer returned`; raise `HTTPException(500)`      | Log `CHAT STEP 4 COMPLETE` and `Chat flow COMPLETE`; return `QueryResponse` |
| backend/main.py | chat     | 337‚Äì339| `except HTTPException`                                                | Log `CHAT STEP 4 FAILED: HTTPException raised`; re-raise same `HTTPException`              | N/A                                                           |
| backend/main.py | chat     | 340‚Äì345| `except Exception as e`                                               | Log `CHAT STEP 4 FAILED: Error processing query: {e}`; raise `HTTPException(500)`          | N/A                                                           |